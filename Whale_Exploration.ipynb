{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5005 unique whale IDs\n",
      "           Image         Id                                               Path\n",
      "0  0000e88ab.jpg  w_f48451c  /n/fs/pvl/dfan/kaggle/humpback-whale/train/000...\n",
      "1  0001f9222.jpg  w_c3d896a  /n/fs/pvl/dfan/kaggle/humpback-whale/train/000...\n",
      "2  00029d126.jpg  w_20df2c5  /n/fs/pvl/dfan/kaggle/humpback-whale/train/000...\n",
      "3  00050a15a.jpg  new_whale  /n/fs/pvl/dfan/kaggle/humpback-whale/train/000...\n",
      "4  0005c1ef8.jpg  new_whale  /n/fs/pvl/dfan/kaggle/humpback-whale/train/000...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Set paths\n",
    "train_path = os.path.abspath('./train')\n",
    "test_path = os.path.abspath('./test')\n",
    "csv_path = os.path.abspath('./train.csv')\n",
    "\n",
    "# Read train.csv into Pandas dataframe\n",
    "train_csv = pd.read_csv(csv_path)\n",
    "print('{} unique whale IDs'.format(len(train_csv['Id'].unique())))\n",
    "# Add absolute image path to make reading easier\n",
    "train_csv['Path'] = [os.path.join(train_path, img) for img in train_csv['Image']]\n",
    "print(train_csv.head())\n",
    "\n",
    "# Explore some whale pics\n",
    "random_whales = train_csv['Path'].sample(5)\n",
    "for whale in random_whales:\n",
    "    img = Image.open(whale)\n",
    "    plt.imshow(img)\n",
    "    plt.show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset subclass for loading images efficiently in memory\n",
    "class WhalesDataset(data.dataset.Dataset):\n",
    "    def __init__(self, is_train, transform):\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return train_csv.shape[0] # training images\n",
    "        return train_csv.shape[0] # testing images\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_type = 'train' if self.is_train else 'test'\n",
    "        whale_id = train_csv['Id'][index]\n",
    "        img_path = train_csv['Path'][index]\n",
    "        img = Image.open(img_path) # 128 x 128 x 3\n",
    "        if self.transform:\n",
    "            img = self.transform(img) # ToTensor converts (HxWxC) -> (CxHxW)\n",
    "        return index, whale_id, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    num_classes = train_csv.shape[0]\n",
    "    # Hyperparameters\n",
    "    num_epochs = 1;\n",
    "    learning_rate = 0.001;\n",
    "    train_params = {'batch_size': 15, 'shuffle': True, 'num_workers': 5}\n",
    "    # Load Data\n",
    "    preprocess_steps = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(200),\n",
    "        transforms.CenterCrop(200),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    train_set = WhalesDataset(is_train = True, transform=preprocess_steps)\n",
    "    train_loader = data.DataLoader(train_set, **train_params)\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = torchvision.models.resnet50(pretrained=True).to(device)\n",
    "    # Freeze all layers\n",
    "    for i, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "    # ImageNet has 1000 classes, so we need to change last layer to accomodate the number of classes we have\n",
    "    imagenet_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(imagenet_features, num_classes)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Train the network\n",
    "    total_steps = len(train_loader)\n",
    "    iterations = []\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (_, whale_ids, images) in enumerate(train_loader):\n",
    "            # Send tensors to GPU\n",
    "            whale_ids = images.to(device) # batch_size x 3 x 128 x 128\n",
    "            images = images.to(device)   # batch_size x 128 x 128\n",
    "\n",
    "            model.train() # reset model to training mode\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            print(outputs.shape)\n",
    "            # Rearrange outputs to batch_size x 128 x 128 x 3 to apply masks\n",
    "            # Output is now _ x 3 (rows of length 3 vectors)\n",
    "            outputs = outputs.permute(0,2,3,1)[masks,:]\n",
    "            truths = normals.permute(0,2,3,1)[masks,:]\n",
    "            loss = get_loss(outputs, truths)\n",
    "            loss = torch.mean(loss)\n",
    "            # use backward() to do backprop on loss variable\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                curr_iter = epoch * len(train_loader) + i\n",
    "                iterations.append(curr_iter)\n",
    "                losses.append(loss.item())\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Batch Loss: {:.4f}'.format\n",
    "                      (epoch+1, num_epochs, i+1, total_steps, loss.item()))\n",
    "                sys.stdout.flush()\n",
    "    \n",
    "    # Calculate loss over entire training set instead of batch\n",
    "    final_acc = evaluate(model, device, train_loader)\n",
    "    print('Final training set accuracy: {}'.format(final_acc))\n",
    "    print('Making predictions on testing set:')\n",
    "    make_predictions(model, True, device, test_loader)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
